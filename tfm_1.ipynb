{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import spacy\n",
    "#importing necessary modules\n",
    "import os\n",
    "import glob\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Execute this line if you are running this code for first time\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing few variable\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Read PDF File and return its Text\n",
    "def pdfReader(pdf_path):\n",
    "    \n",
    "    with open(pdf_path, 'rb') as pdfFileObject:\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObject)\n",
    "        count = pdfReader.numPages\n",
    "        print(\"\\nTotal Pages in pdf = \", count)\n",
    "        \n",
    "        c = 'Y'\n",
    "        start_page = 0\n",
    "        end_page = count-1\n",
    "        c = input(\"Do you want to read entire pdf ?[Y]/N  :  \")\n",
    "        if c == 'N' or c == 'n' :\n",
    "            start_page  = int(input(\"Enter start page number (Indexing start from 0) :  \"))\n",
    "            end_page = int(input(f\"Enter end page number (Less than {count}) : \"))\n",
    "            \n",
    "            if start_page <0 or start_page >= count:\n",
    "                print(\"\\nInvalid Start page given\")\n",
    "                sys.exit()\n",
    "                \n",
    "            if end_page <0 or end_page >= count:\n",
    "                print(\"\\nInvalid End page given\")\n",
    "                sys.exit()\n",
    "                \n",
    "        for i in range(start_page,end_page+1):\n",
    "            page = pdfReader.getPage(i)\n",
    "\n",
    "        return page.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Step 3. Getting Text \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m input_text_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSelect one way of inputting your text  \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m1. Type your Text(or Copy-Paste)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m2. Load from .txt file\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m3. Load from .pdf file\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m4. From Wikipedia Page URL\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_text_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      7\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter your text : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "#Step 3. Getting Text \n",
    "\n",
    "input_text_type = int(input(\"Select one way of inputting your text  \\\n",
    ": \\n1. Type your Text(or Copy-Paste)\\n2. Load from .txt file\\n3. Load from .pdf file\\n4. From Wikipedia Page URL\\n\\n\"))\n",
    "\n",
    "if input_text_type == 1:\n",
    "    text = input(u\"Enter your text : \\n\\n\")\n",
    "\n",
    "elif input_text_type == 2:\n",
    "    txt_path = input(\"Enter file path :  \")\n",
    "    text = file_text(txt_path)\n",
    "    \n",
    "        \n",
    "elif input_text_type == 3:\n",
    "    file_path = input(\"Enter file path :  \")\n",
    "    text = pdfReader(file_path)\n",
    "    \n",
    "elif input_text_type == 4:\n",
    "    wiki_url = input(\"Enter Wikipedia URL to load Article : \")\n",
    "    text = wiki_text(wiki_url)\n",
    "    \n",
    "else:\n",
    "    print(\"Sorry! Wrong Input, Try Again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractor de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the NLP model\n",
    "#https://spacy.io/usage/models\n",
    "#you need to download the spacy model before starting this step. \n",
    "#More info on the website of spacy to download spacy model. \n",
    "#You can also load your own custom made model if you want\n",
    "\n",
    "nlp_model=spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of a dataframe to include the columns \n",
    "df_PA4= pd.DataFrame(columns = ['Text No.','Entities', 'Labels'])\n",
    "#input files path where your pdf files are\n",
    "files_path= 'C:/Users/USUARIO/Desktop/tfm'\n",
    "#reading the path\n",
    "read_files=glob.glob(os.path.join(files_path,\"*.pdf\")) \n",
    "#looping over the pdf files\n",
    "for files in read_files:\n",
    "    #if the filename is clear and distinct\n",
    "    from pathlib import Path\n",
    "    #Extracting the basename of the file\n",
    "    base = os.path.basename(files)\n",
    "    #Extract the filename from the basename of the file\n",
    "    filename=Path(base).stem\n",
    "    #if the filename is not the official name  of the application\n",
    "    #filename=\"DMP_\"+str(i)\n",
    "    text=''\n",
    "    #using pdfplumber for processing the pdf files\n",
    "    with pdfplumber.open(files) as pdf:\n",
    "        for pdf_page in pdf.pages:\n",
    "            single_page_text=pdf_page.extract_text()\n",
    "            text=text+ '\\n' + single_page_text\n",
    "    tx=\"  \".join(text.split('\\n'))\n",
    "    #Load SpaCy Model\n",
    "    docs=nlp_model(tx)\n",
    "    #initialize entities and labels variables\n",
    "    entities = []\n",
    "    labels = []\n",
    "    for ent in docs.ents:\n",
    "        entities.append(ent)\n",
    "        labels.append(ent.label_)\n",
    "    #collecting the entities and the corresponding labels of the file in the loop in a dataframe\n",
    "    df = pd.DataFrame({'Text No.':filename,'Entities':entities,'Labels':labels})\n",
    "    #assigning all the datatypes within df as string\n",
    "    df = df.astype('str')\n",
    "    #dropping the duplicates\n",
    "    df.drop_duplicates(subset=['Text No.','Entities','Labels'], keep=\"first\", inplace=True)\n",
    "    #appending data of the file in the loop \n",
    "    df_PA4 = df_PA4.append(df, ignore_index=True)\n",
    "df_PA4.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NStructure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
